# Step 1: load your DataRobot predictions
preds <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/result-68e04be4b12e0a42bb1233da (1).csv')
# Step 2: load Kaggle test.csv
test <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv')
# Step 3: combine datetime from test.csv with predictions
submission <- test %>%
select(datetime) %>%
bind_cols(preds %>% select(log_count_PREDICTION)) %>%
mutate(count = exp(log_count_PREDICTION)) %>%
select(datetime, count)
# You already have:
# train_raw, test_raw (with datetime parsed)
# mybike_recipe, mybike_prep (prep(mybike_recipe, training = train))
# --- 1) Bake the test set to match baked_train columns ---
baked_test <- bake(mybike_prep, new_data = test_raw)
# Save for DataRobot scoring (NO datetime column; matches baked_train)
vroom_write(baked_test, "data/bike_baked_test.csv", delim = ",")
# --- 2) Also save the raw datetime for later submission merge ---
test_ids <- test_raw %>% select(datetime)
vroom_write(test_ids, "data/test_ids.csv", delim = ",")
library(tidyverse)
# Step 1: load predictions from DataRobot
preds <- read_csv("/Users/chasenielsen/Downloads/result-68e0920453b1fdcff9c18ec3.csv")
# ^ change this path to your actual downloaded file name
# Step 2: load original test.csv for datetime
test <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv')
# Step 3: combine datetime with predictions & back-transform
submission <- test %>%
select(datetime) %>%
bind_cols(preds %>% select(log_count_PREDICTION)) %>%
mutate(
count = expm1(log_count_PREDICTION),  # inverse of log1p
count = pmax(0, round(count))         # ensure non-negative integers
) %>%
select(datetime, count)
# Step 4: save Kaggle submission
write_csv(submission, "submission.csv")
library(tidyverse)
# Step 1: load predictions from DataRobot
preds <- read_csv("/Users/chasenielsen/Downloads/result-68e0920453b1fdcff9c18ec3.csv")
# ^ change this path to your actual downloaded file name
# Step 2: load original test.csv for datetime
test <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv')
# Step 3: combine datetime with predictions & back-transform
submission <- test %>%
select(datetime) %>%
bind_cols(preds %>% select(log_count_PREDICTION)) %>%
mutate(
count = expm1(log_count_PREDICTION),  # inverse of log1p
count = pmax(0, round(count))         # ensure non-negative integers
) %>%
select(datetime, count)
# Step 4: save Kaggle submission
write_csv(submission, "submission2.csv")
library(tidyverse)
library(vroom)
# ==== 0) SET YOUR PATHS ====
preds_path <- "/Users/chasenielsen/Downloads/result-68e0920453b1fdcff9c18ec3.csv"  # DataRobot predictions you downloaded
test_path  <- "/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv" # original Kaggle test.csv
# ==== 1) LOAD ====
preds <- readr::read_csv(preds_path, show_col_types = FALSE)
test  <- readr::read_csv(test_path,  show_col_types = FALSE) %>%
select(datetime) %>%
mutate(datetime = format(as.POSIXct(datetime, tz = "UTC"), "%Y-%m-%d %H:%M:%S"))
# Find the prediction column (e.g., "log_count_PREDICTION")
pred_col <- names(preds)[grepl("_PREDICTION$", names(preds))]
if (length(pred_col) == 0) stop("Couldn't find a *_PREDICTION column in your DataRobot file.")
pred_col <- pred_col[1]
# ==== 2) ALIGN ROWS SAFELY ====
# If your predictions file contains a row identifier, we could join on it.
# Most DR downloads don’t—so we align by row order and validate counts.
if (nrow(preds) != nrow(test)) {
stop(glue::glue("Row count mismatch: preds = {nrow(preds)}, test = {nrow(test)}.
Make sure the predictions were computed on Kaggle's test.csv (should be 6,493 rows)."))
}
# ==== 3) BUILD SUBMISSION (invert log1p -> expm1, clamp & round) ====
submission <- test %>%
bind_cols(preds %>% select(!!pred_col)) %>%
mutate(
count = expm1(.data[[pred_col]]),
count = pmax(0, round(count))
) %>%
select(datetime, count)
# sanity checks
stopifnot(nrow(submission) == 6493)
stopifnot(identical(names(submission), c("datetime", "count")))
# datetime must be exactly "YYYY-MM-DD HH:MM:SS"
stopifnot(!any(grepl("T|\\+", submission$datetime)))  # no ISO T or timezone
# ==== 4) SAVE WITH VROOM ====
fs::dir_create("submissions")
vroom::vroom_write(submission, "submissions/submission.csv", delim = ",")
# Optional: quick peek
print(head(submission, 5))
# paths (update if needed)
preds_path <- "/Users/chasenielsen/Downloads/result-68e0920453b1fdcff9c18ec3.csv"
test_path  <- "/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv"
preds <- readr::read_csv(preds_path, show_col_types = FALSE)
test  <- readr::read_csv(test_path,  show_col_types = FALSE) %>%
select(datetime) %>%
mutate(datetime = format(as.POSIXct(datetime, tz = "UTC"), "%Y-%m-%d %H:%M:%S"))
# find prediction column (e.g., "log_count_PREDICTION")
pred_col <- names(preds)[grepl("_PREDICTION$", names(preds))][1]
# build submission: no rounding this time
submission <- test %>%
bind_cols(preds %>% select(!!pred_col)) %>%
mutate(
count = expm1(.data[[pred_col]]),
count = pmax(0, count)     # keep non-negative, but DON'T round
) %>%
select(datetime, count)
# save
fs::dir_create("submissions")
vroom::vroom_write(submission, "submissions/submission_no_round.csv", delim = ",")
# quick sanity checks (optional)
print(head(submission, 5))
summary(submission$count)
# ======================
# Libraries
# ======================
library(tidyverse)
library(lubridate)
library(lightgbm)
library(vroom)
# ======================
# Read data
# ======================
train <- read_csv("train.csv")
# ======================
# Libraries
# ======================
library(tidyverse)
library(lubridate)
library(lightgbm)
library(vroom)
# ======================
# Read data
# ======================
train <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/train.csv')
test  <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv')
# ======================
# Feature engineering
# ======================
add_features <- function(df) {
df %>%
mutate(
hour     = hour(datetime),
wday     = wday(datetime),      # day of week
month    = month(datetime),
year     = year(datetime),
is_weekend = if_else(wday %in% c(1,7), 1, 0)
)
}
train <- add_features(train)
test  <- add_features(test)
# log1p transform target
train$log_count <- log1p(train$count)
# ======================
# Prepare matrices for LightGBM
# ======================
features <- setdiff(names(train), c("datetime", "count", "casual", "registered", "log_count"))
dtrain <- lgb.Dataset(data = as.matrix(train[, features]),
label = train$log_count)
# ======================
# Train LightGBM model
# ======================
params <- list(
objective = "regression",
metric = "rmse",
learning_rate = 0.05,
num_leaves = 64,
feature_fraction = 0.8,
bagging_fraction = 0.8,
bagging_freq = 5,
min_data_in_leaf = 20
)
set.seed(123)
lgb_model <- lgb.train(
params,
dtrain,
nrounds = 2000,
valids = list(train = dtrain),
early_stopping_rounds = 100,
verbose = 50
)
# ======================
# Predict on test
# ======================
preds_log <- predict(lgb_model, as.matrix(test[, features]))
preds     <- pmax(0, expm1(preds_log))   # invert log1p, clamp at 0
# ======================
# Build submission
# ======================
submission <- tibble(
datetime = format(as.POSIXct(test$datetime), "%Y-%m-%d %H:%M:%S"),
count    = preds
)
vroom_write(submission, "submission_lightgbm.csv", delim = ",")
cat("Submission saved -> submission_lightgbm.csv\n")
# ========= Packages =========
library(tidyverse)
library(lubridate)
library(lightgbm)
library(glmnet)
library(ranger)
library(vroom)
# ========= 1) Load =========
train <- read_csv("train.csv", show_col_types = FALSE)
# ========= 1) Load =========
train <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/train.csv', show_col_types = FALSE)
test  <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv',  show_col_types = FALSE)
# ========= 2) Feature engineering (strong, but safe) =========
fe <- function(df) {
df %>%
mutate(
hour        = hour(datetime),
wday        = wday(datetime),              # 1=Sun ... 7=Sat
month       = month(datetime),
year        = year(datetime),
is_weekend  = as.integer(wday %in% c(1,7)),
rush_morn   = as.integer(hour %in% 7:9),
rush_eve    = as.integer(hour %in% 17:19),
hour_sin    = sin(2*pi*hour/24),
hour_cos    = cos(2*pi*hour/24),
wday_sin    = sin(2*pi*(wday-1)/7),
wday_cos    = cos(2*pi*(wday-1)/7),
temp2       = temp^2,
atemp2      = atemp^2,
hum2        = humidity^2,
wind2       = windspeed^2,
temp_x_hum  = temp * humidity,
atemp_minus_temp = atemp - temp,
weather     = pmin(weather, 3)             # map 4 -> 3 as in your recipe
)
}
train <- fe(train)
test  <- fe(test)
# Target on log1p scale (matches your class pipeline)
train <- train %>% mutate(log_count = log1p(count))
# Predictors (drop leakage/helper cols)
drop_cols <- c("datetime","count","casual","registered","log_count")
predictors <- setdiff(names(train), drop_cols)
# ========= 3) Train/Validation split (time-ordered) =========
train <- arrange(train, datetime)
n <- nrow(train); cut <- floor(0.8*n)
trn <- train[1:cut, ]
val <- train[(cut+1):n, ]
x_trn <- as.matrix(trn[, predictors])
y_trn <- trn$log_count
x_val <- as.matrix(val[, predictors])
y_val <- val$log_count
x_all <- as.matrix(train[, predictors])
x_test <- as.matrix(test[, predictors])
# ========= 4) Model 1: LightGBM (tuned with CV on train part) =========
dtrn <- lgb.Dataset(data = x_trn, label = y_trn)
params <- list(
objective = "regression",
metric = "rmse",
learning_rate = 0.05,
num_leaves = 64,
feature_fraction = 0.9,
bagging_fraction = 0.9,
bagging_freq = 5,
min_data_in_leaf = 25
)
set.seed(123)
cv <- lgb.cv(
params = params,
data   = dtrn,
nrounds = 5000,
nfold   = 5,
early_stopping_rounds = 200,
verbose = -1
)
best_iter <- cv$best_iter
lgb_trn <- lgb.train(params, dtrn, nrounds = best_iter, verbose = -1)
pred_val_lgb  <- predict(lgb_trn, x_val)
# Retrain on all data for final test prediction
lgb_all <- lgb.train(params, lgb.Dataset(x_all, label = train$log_count),
nrounds = best_iter, verbose = -1)
pred_test_lgb <- predict(lgb_all, x_test)
# ========= 5) Model 2: Elastic Net (glmnet) =========
set.seed(123)
cv_en <- cv.glmnet(x_trn, y_trn, alpha = 0.5, family = "gaussian", nfolds = 5)
en_trn  <- glmnet(x_trn, y_trn, alpha = 0.5, lambda = cv_en$lambda.min)
pred_val_en  <- as.numeric(predict(en_trn, x_val))
en_all <- glmnet(x_all, train$log_count, alpha = 0.5, lambda = cv_en$lambda.min)
pred_test_en <- as.numeric(predict(en_all, x_test))
# ========= 6) Model 3: Random Forest (ranger) =========
set.seed(123)
rf_trn <- ranger(
dependent.variable.name = "log_count",
data = trn[, c("log_count", predictors)],
num.trees = 1200,
mtry = max(3, floor(sqrt(ncol(x_trn)))),
min.node.size = 5,
importance = "impurity"
)
pred_val_rf  <- predict(rf_trn, val[, predictors])$predictions
rf_all <- ranger(
dependent.variable.name = "log_count",
data = train[, c("log_count", predictors)],
num.trees = 1200,
mtry = max(3, floor(sqrt(ncol(x_all)))),
min.node.size = 5
)
pred_test_rf <- predict(rf_all, test[, predictors])$predictions
# ========= 7) Blend weights from validation (simple grid on simplex) =========
rmse <- function(a,b) sqrt(mean((a-b)^2))
grid <- seq(0,1,by=0.05)
best <- list(rmse=Inf,w1=NA,w2=NA,w3=NA)
for (w1 in grid) for (w2 in grid) {
w3 <- 1 - w1 - w2
if (w3 < 0) next
pred_blend <- w1*pred_val_lgb + w2*pred_val_en + w3*pred_val_rf
s <- rmse(y_val, pred_blend)
if (s < best$rmse) best <- list(rmse=s,w1=w1,w2=w2,w3=w3)
}
best  # peek at chosen weights
# ========= 8) Predict test with blended log-preds, then invert log1p =========
pred_test_log <- best$w1*pred_test_lgb + best$w2*pred_test_en + best$w3*pred_test_rf
pred_test     <- pmax(0, expm1(pred_test_log))  # NO rounding
# ========= 9) Save Kaggle submission =========
submission <- tibble(
datetime = format(as.POSIXct(test$datetime), "%Y-%m-%d %H:%M:%S"),
count    = pred_test
)
vroom_write(submission, "submission_blend.csv", delim = ",")
cat("Saved: submission_blend.csv\n")
install.packages("nnls")
# ========= Packages =========
library(tidyverse)
library(lubridate)
library(lightgbm)
library(glmnet)
library(ranger)
library(vroom)
library(nnls)
# ========= 1) Load =========
train <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/train.csv', show_col_types = FALSE)
test  <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleBikeShare/data/test.csv',  show_col_types = FALSE)
# ========= 2) Feature engineering =========
fe <- function(df) {
df %>%
mutate(
hour        = hour(datetime),
wday        = wday(datetime),
month       = month(datetime),
year_fac    = factor(year(datetime)),   # treat year as factor
is_weekend  = as.integer(wday %in% c(1,7)),
rush_morn   = as.integer(hour %in% 7:9),
rush_eve    = as.integer(hour %in% 17:19),
hour_sin    = sin(2*pi*hour/24),
hour_cos    = cos(2*pi*hour/24),
wday_sin    = sin(2*pi*(wday-1)/7),
wday_cos    = cos(2*pi*(wday-1)/7),
temp2       = temp^2,
atemp2      = atemp^2,
hum2        = humidity^2,
wind2       = windspeed^2,
temp_x_hum  = temp * humidity,
atemp_minus_temp = atemp - temp,
weather     = pmin(weather, 3)
)
}
train <- fe(train) %>% mutate(log_count = log1p(count))
test  <- fe(test)
drop_cols <- c("datetime","count","casual","registered","log_count")
predictors <- setdiff(names(train), drop_cols)
# ========= 3) Time-ordered split =========
train <- arrange(train, datetime)
n <- nrow(train); cut <- floor(0.8*n)
trn <- train[1:cut, ]
val <- train[(cut+1):n, ]
x_trn <- as.matrix(trn[, predictors])
y_trn <- trn$log_count
x_val <- as.matrix(val[, predictors])
y_val <- val$log_count
x_all <- as.matrix(train[, predictors])
x_test <- as.matrix(test[, predictors])
# ========= 4) Model 1: LightGBM =========
dtrn <- lgb.Dataset(data = x_trn, label = y_trn)
params <- list(
objective = "regression",
metric = "rmse",
learning_rate = 0.035,   # lower LR
num_leaves = 96,         # deeper trees
feature_fraction = 0.9,
bagging_fraction = 0.9,
bagging_freq = 5,
min_data_in_leaf = 20
)
set.seed(123)
cv <- lgb.cv(
params = params,
data   = dtrn,
nrounds = 5000,
nfold   = 5,
early_stopping_rounds = 300,
verbose = -1
)
best_iter <- cv$best_iter
lgb_trn <- lgb.train(params, dtrn, nrounds = best_iter, verbose = -1)
pred_val_lgb  <- predict(lgb_trn, x_val)
lgb_all <- lgb.train(params, lgb.Dataset(x_all, label = train$log_count),
nrounds = best_iter, verbose = -1)
pred_test_lgb <- predict(lgb_all, x_test)
# ========= 5) Model 2: Elastic Net =========
set.seed(123)
cv_en <- cv.glmnet(x_trn, y_trn, alpha = 0.5, family = "gaussian", nfolds = 5)
en_trn  <- glmnet(x_trn, y_trn, alpha = 0.5, lambda = cv_en$lambda.min)
pred_val_en  <- as.numeric(predict(en_trn, x_val))
en_all <- glmnet(x_all, train$log_count, alpha = 0.5, lambda = cv_en$lambda.min)
pred_test_en <- as.numeric(predict(en_all, x_test))
# ========= 6) Model 3: Random Forest =========
set.seed(123)
rf_trn <- ranger(
dependent.variable.name = "log_count",
data = trn[, c("log_count", predictors)],
num.trees = 1200,
mtry = max(3, floor(sqrt(ncol(x_trn)))),
min.node.size = 5
)
pred_val_rf  <- predict(rf_trn, val[, predictors])$predictions
rf_all <- ranger(
dependent.variable.name = "log_count",
data = train[, c("log_count", predictors)],
num.trees = 1200,
mtry = max(3, floor(sqrt(ncol(x_all)))),
min.node.size = 5
)
pred_test_rf <- predict(rf_all, test[, predictors])$predictions
# ========= 7) NNLS stacking =========
Z_val <- cbind(pred_val_lgb, pred_val_en, pred_val_rf)
fit_nnls <- nnls(Z_val, y_val)
w <- coef(fit_nnls); if (sum(w)==0) w[] <- 1
w <- as.numeric(w / sum(w))
print(w)
pred_test_log <- w[1]*pred_test_lgb + w[2]*pred_test_en + w[3]*pred_test_rf
pred_test     <- pmax(0, expm1(pred_test_log))   # continuous, no rounding
# ========= 8) Save submission =========
submission <- tibble(
datetime = format(as.POSIXct(test$datetime), "%Y-%m-%d %H:%M:%S"),
count    = pred_test
)
vroom_write(submission, "submission_blend_nnls.csv", delim = ",")
cat("Saved: submission_blend_nnls.csv\n")
library(tidyverse)
library(vroom)
library(readr)
library(GGally)
library(patchwork)
library(tidymodels)
library(recipes)
library(lubridate)
geted()
getwd()
setwd('/Users/chasenielsen/Documents/Stat348/KaggleAmazon')
getwd()
test <- read_csv('/Users/chasenielsen/Documents/Stat 348/KaggleAmazon/test.csv')
test <- read_csv("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
library(tidyverse)
library(vroom)
library(readr)
library(GGally)
library(patchwork)
library(tidymodels)
library(recipes)
library(lubridate)
test <- read_csv("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
test <- vroom("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
test <- vroom("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
test %>%
count(ACTION) %>%
mutate(prop = n / sum(n)) %>%
ggplot(aes(x = factor(ACTION), y = prop, fill = factor(ACTION))) +
geom_col() +
scale_y_continuous(labels = scales::percent_format()) +
labs(x = "Action (0 = denied, 1 = approved)",
y = "Proportion of records",
title = "Class Balance: Denied vs Approved") +
theme_minimal()
test <- vroom("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
head(test)
test <- vroom("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
test %>%
summarise(across(everything(), ~ n_distinct(.x))) %>%
pivot_longer(everything(), names_to = "feature", values_to = "unique_values") %>%
ggplot(aes(x = reorder(feature, unique_values), y = unique_values)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Number of Unique Values per Feature",
x = "Feature", y = "Unique Categories") +
theme_minimal()
test <- vroom("/Users/chasenielsen/Documents/Stat348/KaggleAmazon/test.csv")
test %>%
summarise(across(everything(), ~ n_distinct(.x))) %>%
pivot_longer(everything(), names_to = "feature", values_to = "unique_values") %>%
ggplot(aes(x = reorder(feature, unique_values), y = unique_values)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Number of Unique Values per Feature",
x = "Feature", y = "Unique Categories") +
theme_minimal()
test %>%
count(ROLE_DEPTNAME, sort = TRUE) %>%
slice_max(n, n = 20) %>%
ggplot(aes(x = reorder(as.factor(ROLE_DEPTNAME), n), y = n)) +
geom_col(fill = "orange") +
coord_flip() +
labs(title = "Top 20 Most Common ROLE_DEPTNAME Values",
x = "ROLE_DEPTNAME", y = "Count") +
theme_minimal()
